# Express Web API to Amazon Elastic Kubernetes Service (EKS)

The architecture of this Kubernetes deployment is designed with the following assumptions:
* That an NGINX Ingress controller running in cluster can itself sufficiently handle requests without the help of an external Network Load Balancer
* That you intend to serve API requests over HTTPS only, and that Let's Encrypt is a sufficient authority for your situation
* That your outgoing egress traffic from pods does not require that it come from any specific IP address or range (i.e. the services your API hits do not whitelist IPs)

If any of these assumptions are not true, it is possible to extend this setup to accomodate the additional requirement(s). Those instructions are beyond the scope of this more simple setup.

## Cloud Services used
* AWS Elastic Kubernetes Service (EKS)
* AWS Elastic Container Registry (ECR)
* Let's Encrypt Certificate Authority

## Pre-requisites

1. Install Zip, JQ, Gettext (`envsubst` command)
```bash
$ brew install zip jq gettext
$ echo 'export PATH="/usr/local/opt/gettext/bin:$PATH"' >> ~/.bash_profile
```

2. Install AWS CLI
```bash
$ curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
$ unzip awscli-bundle.zip
$ sudo ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
```

3. Configure AWS CLI Profile
```bash
$ aws configure --profile profile_name
```

4. Install `aws-iam-authenticator`
```bash
$ brew install aws-iam-authenticator
```

5. Install `eksctl`
```bash
$ brew tap weaveworks/tap
$ brew install weaveworks/tap/eksctl
```

6. Install `kubectl`
```bash
$ brew install kubectl
```

7. Install `helm`
```bash
$ curl -o get_helm.sh https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get
$ chmod +x get_helm.sh
$ ./get_helm.sh
```

## Usage

Copy all files in this directory to the root of your Express Web API app. Then open both `deploy-cluster.sh` and `deploy.sh` and replace the following variables at the top:

<table>
  <tr>
    <td><strong>Variable name</strong></td>
    <td><strong>Requirement</strong></td>
    <td><strong>Description</strong></td>
  </tr>

  <tr>
    <td>AWS_PROFILE</td>
    <td>Required</td>
    <td>The name of the profile you used in <code>aws configure --profile profile_name</code></td>
  </tr>

  <tr>
    <td>AWS_ACCOUNT_ID</td>
    <td>Do not modify (<code>deploy.sh</code> only)</td>
    <td>This is needed by the naming convention for Docker images in the AWS Elastic Container Registry. This can be found in your <a href="https://console.aws.amazon.com/iam" target="_blank">IAM dashboard</a>. This should be retrieved via <code>aws</code> command.</td>
  </tr>

  <tr>
    <td>CLUSTER_NAME</td>
    <td>Required</td>
    <td>The name of your cluster. You can name this anything you want.</td>
  </tr>

  <tr>
    <td>VM_ID</td>
    <td>Required (<code>deploy.sh</code> only)</td>
    <td>The name of your app. You can name this anything you want, but you should aim for this name to describe your app in a short word because it will be used to name all Kubernetes objects (deployment, service, ingress, secret, etc).
  </tr>

  <tr>
    <td>REGION</td>
    <td>Required</td>
    <td>The AWS region you'd like to use for this deployment. This is used to determine where the Kubernetes cluster will be deployed.</td>
  </tr>

  <tr>
    <td>VERSION</td>
    <td>Do not modify (<code>deploy.sh</code> only)</td>
    <td>The version by default will update itself based on your Git repository's most recent commit SHA. Only modify this if you have a better version assignment scheme.</td>
  </tr>

  <tr>
    <td>DOMAIN</td>
    <td>Required</td>
    <td>The domain of your API deployment. This will be used as the basis for the SSL certificate generated by the Cert Manager.</td>
  </tr>

  <tr>
    <td>NODE_TYPE</td>
    <td>Required (<code>deploy-cluster.sh</code> only)</td>
    <td>The class and size of the AWS instances to be used as nodes in this Kubernetes cluster (ex: <code>m5.2xlarge</code>).</td>
  </tr>

  <tr>
    <td>ZONES</td>
    <td>Required (<code>deploy-cluster.sh</code> only)</td>
    <td>This is a comma-delimited set of zones where the cluster is allowed to provision nodes. The zones must match the <code>REGION</code> parameter, and must all support the <code>NODE_TYPE</code> class of instances.</td>
  </tr>
</table>

**NOTE**: for any variable name found in *both* `deploy.sh` and `deploy-cluster.sh`, the corresponding values MUST be equivalent across both files.

Then check these files into your repository.

To deploy your cluster on EKS:
```bash
$ ./deploy-cluster.sh
```

Then set your domain's DNS record (A or CNAME) to this cluster's NGINX Ingress' external IP:
```bash
$ kubectl get svc -n nginx-ingress
NAME                            TYPE           CLUSTER-IP       EXTERNAL-IP                                                              PORT(S)                      AGE
nginx-ingress-controller        LoadBalancer   10.100.110.116   qqqag40c1778e11eaa1870ebb5761989-215797116.us-east-1.elb.amazonaws.com   80:31884/TCP,443:30311/TCP   1d
```
This must be done **before** you run `deploy.sh` because when the Ingress is first deployed, the Cert Manager challenge used to issue the SSL certificate is done by polling your domain's DNS entry.

Create your secrets manifest:
```bash
$ cp k8s/deployment-secret.yaml.sample k8s/deployment-secret.yaml
```

Add this resulting file to your `.gitignore`:
```bash
$ echo k8s/deployment-secret.yaml >> .gitignore
```

For each variable in the secrets manifest, fill in the Base 64 encoded string:
```bash
$ echo -n <raw string> | base64
```
Don't forget to use the `-n` flag, otherwise the secrets will include a newline character which will be interpreted literally.

If you want to **add** a new variable to the secrets manifest to be used, be sure to update `deployment.yaml` with another entry in the `spec.template.spec.containers[].env` array:
```bash
spec:
  ...
  template:
    ...
    spec:
      containers:
      ...
      - ...
        ...
        env:
        ...
        - name: "NEW_VAR"
          valueFrom:
            secretKeyRef:
              name: deployment-secret
              key: NEW_VAR
```

Finally, to deploy the app from the command line, run:
```bash
$ ./deploy.sh
```

## Security

By default, the scripts will deploy the cluster behind a VPC, which means it's not accessible via the public Internet. The bastion deploy script is used to deploy a bastion host within the cluster's VPC that you can SSH into. Get it set up by running:
```bash
$ ./bastion-deploy.sh
```

The deploy script will create a `.pem` key to get into the bastion host. Make sure to place this key in the bucket [https://console.aws.amazon.com/s3/buckets/zenrpa-bastion](https://console.aws.amazon.com/s3/buckets/zenrpa-bastion).

SSH into the bastion host like this:
```bash
$ ssh -i zenrpa-cluster-bastion.pem ubuntu@ec2-x-x-x-x.amazonaws.com
$ (in host) AWS Access Key ID:
$ (in host) AWS Secret Access Key:
```

This will automatically set the Kube config to the `zenrpa-cluster`, assuming your access key allows for it. Use your own access key from your own IAM, which should have sufficient privileges for the cluster. If not, you'll get errors when running any `kubectl` commands.

For security, upon exiting your SSH session, the bastion server's local kubeconfig and AWS credentials will be wiped, and you'll be asked to provide a key again upon the next SSH session. For extra security, upon entering a new SSH session, the local kubeconfig and AWS credentials will also be wiped then.
